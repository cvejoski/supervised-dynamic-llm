{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff9906-c7ba-4327-a2b0-b2b04f61f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "from kiwissenbase.data import dataloaders\n",
    "from kiwissenbase.data.datasets import CaltechPedestrian\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d847f70-5621-4aae-8cce-5bb754ec0cc0",
   "metadata": {},
   "source": [
    "## create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568b961-47a9-4135-8e00-ae9d7ca02ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_args = {\"root_dir\": \"/data/anna/data/caltech_dataset/\",\n",
    "                    \"batch_size\": 8,\n",
    "                    \"validation_batch_size\": 4,\n",
    "                    \"num_workers\": 0,\n",
    "                    \"pin_memory\": True,\n",
    "                    #\"collate_fn\": collate_fn,\n",
    "                    \"normal_mean\": (0.5, 0.5, 0.5),\n",
    "                    \"normal_std\": (0.5, 0.5, 0.5),\n",
    "                    \"different_size_target\": True,\n",
    "                    \"subset\": \"annotated-pedestrians\",                    \n",
    "                    \"target_transform\":{\"module\": \"kiwissenbase.models.object_detection\",\n",
    "                                        \"class_name\": \"FasterRCNN\",\n",
    "                                        \"method_name\": \"target_transform\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f4ad6-b32c-43b6-b837-9fe654d7a969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = dataloaders.CaltechPedastrianDataLoader(device=\"cpu\", **data_loader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7f25f-89e9-4f00-b2df-01766556fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecde4b9-79a7-4c66-bbc9-edf466dea978",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.test.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93f1e4-f847-424e-b4de-825d07c48611",
   "metadata": {},
   "source": [
    "## load and test saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6291c-71df-4db4-b25b-6f35c6c0fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"/data/anna/pedestrian_detection_models/faster_rcnn_tuned_Caltech.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47d7aa-deef-4b32-b1da-566dfaff35b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1a346-385e-476e-8593-caa8649b85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model architecture and adapt output\n",
    "import torchvision \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn()\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6a4da-f2b1-4e89-a1e3-ee1832ed9817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a42d2a-c058-4306-b174-c616b53e26f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9553abf1-990a-4172-a207-a3333220e18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026a0b5-78e5-4015-8aeb-fd590eb64d6d",
   "metadata": {},
   "source": [
    "## register forward hooks on the dissected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596c956-2823-417e-bd6b-9cacb2c942d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        unit_activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0818bf-b073-48e8-9c59-77286c1c6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_activations = {}\n",
    "conv_unit = \"backbone.body.layer4[1].conv2\"\n",
    "eval(f\"model.{conv_unit}.register_forward_hook\")(get_activation(conv_unit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee5c6c-f469-4bc8-a5eb-6f8e41aac360",
   "metadata": {},
   "source": [
    "### test model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2f736-0576-4703-af7e-f8b2944d8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,targets = next(iter(loader.test.dataset))\n",
    "image.to(device)\n",
    "predictions = model([image.to(device)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78383ff-5b80-4d8e-99e2-f77d8d35089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08432adb-3ddc-4eb7-a0f0-39189fc7b485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unit_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828caf3-14e0-46cb-8a2a-1a0109b181a4",
   "metadata": {},
   "source": [
    "## get unit activation (max and average activation for each image) for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bc202-924f-472b-8171-789afaf45933",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_activations = {}\n",
    "conv_unit = \"backbone.body.layer4[1].conv2\"\n",
    "eval(f\"model.{conv_unit}.register_forward_hook\")(get_activation(conv_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eaca7e-6d37-4a6a-88ba-bf4dc1ab7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44715ec-8f6d-40b1-b110-f103c9dccbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_activations = []\n",
    "avg_activations = []\n",
    "pedestrian_image = []\n",
    "detected_pedestrian_image = []\n",
    "all_targets = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for local_batch in tqdm(loader.test):\n",
    "        pedestrian_image.extend([any(item[\"labels\"]==1) for item in local_batch[1]])\n",
    "        local_batch_images = torch.stack(local_batch[0]).to(device)\n",
    "        all_targets.extend(local_batch[1])\n",
    "        output = model(local_batch_images)\n",
    "        output_cpu = [{\"boxes\": item[\"boxes\"].to(\"cpu\"), \"labels\": item[\"labels\"].to(\"cpu\"), \"scores\": item['scores'].to(\"cpu\")}for item in output]\n",
    "        all_predictions.extend(output_cpu)\n",
    "        detected_pedestrian_image.extend([any(item[\"labels\"]==1) for item in output])\n",
    "        for activation in unit_activations[conv_unit]:\n",
    "            flat_tensor = torch.flatten(activation, start_dim=1)\n",
    "            max_activations.append(torch.max(flat_tensor, dim=1)[0])\n",
    "            avg_activations.append(torch.mean(flat_tensor, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b0727d-74ea-416c-a5e4-0bd97595756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total images\", len(pedestrian_image))\n",
    "print(\"images with at least one labelled pedestrian\", sum(pedestrian_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d2062c-0c28-4315-8596-8f50cc24deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"images with at least one detected pedestrian\", sum(detected_pedestrian_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649d7db-9c71-4e0a-9f8a-8d58167bc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_activations_tensor = torch.stack(max_activations)\n",
    "avg_activations_tensor = torch.stack(avg_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0ed89a-a8eb-43cc-b4ab-2d10d863229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_activations_numpy = avg_activations_tensor.detach().to(\"cpu\").numpy()\n",
    "max_activations_numpy = max_activations_tensor.detach().to(\"cpu\").numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f69bca-7237-4a8f-b8b1-eacfd729a0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6bef1-6182-4a68-802d-6b4ba4377824",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_activations[conv_unit].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34df160-d9c1-4520-a666-d68a44876bf2",
   "metadata": {},
   "source": [
    "## Read in the netdissect result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7131fa-751e-4946-b217-03a1dc4f7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_result = \"/data/anna/results/pytorch_fasterrcnn_resnet50_fpn_caltech_backbone.body.layer4[1].conv2/tally.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fea58-8b68-4e5f-b96e-aa52b33f5bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [line for line in csv.reader(open(path_to_result))]\n",
    "data_all = [{\"unit\": int(item[0])-1, \"concept\":item[2], \"score\":item[3]} for item in data[1:]]\n",
    "data_top = data_all[:30]\n",
    "print(\"Top scoring units\\n\")\n",
    "pd.DataFrame(data_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d8c1a2-312b-41fc-b71c-68cc63f30934",
   "metadata": {},
   "source": [
    "### find the relevant detectors from netdissect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34695625-e355-4bc7-bd2d-2d91423ae207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all concepts in layer\")\n",
    "print(set([item[2] for item in data[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80075c34-44d6-46c3-966d-42fc058f08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_concepts = [\"head\", \"hair\", \"arm\", \"wheel\", \"car\", \"sidewalk\",\"road\",\"neck\",\"mouth\",\"person\",\"leg\",\"back\",\"foot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0300272-8a57-4257-b533-f49d5f814171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_top_relevant = [{\"unit\": int(item[0])-1, \"concept\":item[2], \"score\":item[3]} for item in data[1:] if item[2] in relevant_concepts][:30]\n",
    "print(\"Top scoring relevant units\\n\")\n",
    "pd.DataFrame(data_top_relevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff62806-1aef-4507-a090-962f8b0d1653",
   "metadata": {},
   "source": [
    "## check correlation of detector units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de64cd-88fe-45a8-8bbc-5a47328fcb67",
   "metadata": {},
   "source": [
    "### select metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3469efcc-79a1-4630-b4a1-046473af9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = avg_activations_numpy\n",
    "#metric = max_activations_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67cbb44-a929-41a8-8ba3-c208fdff0ac8",
   "metadata": {},
   "source": [
    "### select units to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85f955-30ac-4172-9361-598cb0d2b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit1 = 97\n",
    "unit2 = 510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106970ae-ac2b-4860-98bc-ebece84546d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = metric[:,unit1]\n",
    "y = metric[:,unit2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0cb21-921b-49af-ab92-c32e2e8a4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit1_display = [f\"{item[0]}_{item[2]}_{round(float(item[3]),3)}\" for item in data[1:] if int(item[0])==unit1+1][0]\n",
    "unit2_display = [f\"{item[0]}_{item[2]}_{round(float(item[3]),3)}\" for item in data[1:] if int(item[0])==unit2+1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e3aa8-0d0a-4137-9d06-aa819d0e4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.xlabel(f\"unit {unit1_display}\")\n",
    "plt.ylabel(f\"unit {unit2_display}\")\n",
    "plt.title(f\"correllation {round(pearsonr(x,y)[0],3)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c2e98-f354-4117-8489-dd3cd8d9b169",
   "metadata": {},
   "source": [
    "### calculate correllation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcef923-d129-4519-9710-72d01f7ac286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_data = data_top\n",
    "selected_data = data_top_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3ba37c-2170-4b83-b519-6f8956d872c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correllation = np.zeros((len(selected_data),len(selected_data)))\n",
    "axes_labels = [f\"{item['unit']}_{item['concept']}_{round(float(item['score']),3)}\" for item in selected_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2378b65a-02e8-446b-a9eb-b290440f15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit_ind1,unit1 in tqdm(enumerate(selected_data)):\n",
    "    for unit_ind2,unit2 in enumerate(selected_data[unit_ind1:]):\n",
    "        x = metric[:,unit1[\"unit\"]]\n",
    "        y = metric[:,unit2[\"unit\"]]\n",
    "        r = pearsonr(x,y)[0]\n",
    "        cross_correllation[unit_ind1,unit_ind1+unit_ind2] = cross_correllation[unit_ind1+unit_ind2,unit_ind1] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a3e7e-85b1-45f5-8650-b912a352a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(13,13)})\n",
    "\n",
    "ax = sns.heatmap(cross_correllation, linewidth=0.5,cmap=\"seismic\",vmin=-1,vmax=1)\n",
    "ax.set_xticks(np.arange(0.5,30.5,1), axes_labels,rotation=90)\n",
    "ax.set_yticks(np.arange(0.5,30.5,1), axes_labels, rotation=0)\n",
    "#ax.set_xticklabels(axes_labels, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4406f0a3-660e-4b54-9f6e-069a45c50c94",
   "metadata": {},
   "source": [
    "## examine single detectors with repsect to activation for pedestrian vs non-pedestrian images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892a2f8-8036-467a-9c8e-d831a8aa87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd90b0f-de4b-42ce-ac90-e238fddf91ca",
   "metadata": {},
   "source": [
    "### examine metric for pdestrian vs non-pedestrian images (detected) - max seems to be working better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc7899-1075-4505-a411-a7c507204a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric = avg_activations_numpy\n",
    "metric = max_activations_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd79ccd-dbd3-4c9f-98e7-ddaa7a866c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_data = data_top\n",
    "selected_data = data_top_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba5ca88-0214-4094-a348-e9e7c92b4b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bc498-8466-4a34-aff3-d3921647b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 327\n",
    "# max activation, 327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8bba6-1a94-459f-be30-9388f9814ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pedestrian_activations = [activation[unit] for activation,ped_prsent in zip(metric,detected_pedestrian_image) if ped_prsent] \n",
    "non_pedestrian_activations = [activation[unit] for activation,ped_prsent in zip(metric,detected_pedestrian_image) if not ped_prsent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e9592-39ac-4c5a-95eb-88ad971117af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pedestrian_activations),len(non_pedestrian_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085e062-662a-4bb2-a21d-46d7ed26f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean/std metric in positive predictions(pedestrian detected)\", np.mean(pedestrian_activations), np.std(pedestrian_activations))\n",
    "print(\"mean/std metric in negative predictions(no pedestrian detected)\", np.mean(non_pedestrian_activations), np.std(non_pedestrian_activations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3d8ce-853e-48eb-87e4-2e362de79402",
   "metadata": {},
   "source": [
    "### visualise the two populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f0723-9b15-4d2e-b54e-7cfc3cf469c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = [ttest_ind(non_pedestrian_activations, pedestrian_activations)[1],\n",
    "            mannwhitneyu(non_pedestrian_activations, pedestrian_activations)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff484bee-b833-425c-97db-25a5873212c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept = [item['concept'] for item in selected_data if item['unit']==unit][0]\n",
    "figure_title = f\"unit: {unit} - concept: {concept} p_values: Ttest:{round(p_values[0],5)}, Mann-Whitney test:{round(p_values[1],5)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be0aa0-b5d0-4b14-9634-81035fe95ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize=(15,5)) # Instantiate figure and axes object\n",
    "axes[0].hist(non_pedestrian_activations, label=\"nums1\", histtype=\"step\", density=True, linewidth=2) # Plot histogram of nums1\n",
    "axes[0].hist(pedestrian_activations, label=\"nums2\", histtype=\"step\", density=True, linewidth=2) # Plot histogram of nums2\n",
    "axes[0].legend([\"no pedestrian detection\", \">=1 pedestrian detection\"])\n",
    "axes[1].boxplot([non_pedestrian_activations,pedestrian_activations])\n",
    "axes[1].set_xticklabels([\"no pedestrian \\ndetection\", \">=1 pedestrian\\n detection\"])\n",
    "fig.suptitle(figure_title,fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb220254-507d-4090-88a4-1b5dbc7582bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06dfa98-5f5c-4f08-999f-4566d9525892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba845e-2d51-4255-99bc-ceb4eed03aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c57c8-1915-4873-87a3-791d545ab407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62689038-9919-4c92-9225-09a3d0c3d51e",
   "metadata": {},
   "source": [
    "## todo how to isolate and examine detectors against individual pedestrian predections in an image\n",
    "\n",
    "for an image with false classifications (fps/fns) project activation of unit back to input image\n",
    "\n",
    "get activation around expected area of missed bounding box / area around prediction of false bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d19a6-9de0-49e4-bde8-5f1ebb1581e0",
   "metadata": {},
   "source": [
    "## todo check behaviour for fp/tp/fn/tn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f66bfd-e111-48db-bf6f-beb7a5a1d26b",
   "metadata": {},
   "source": [
    "## todo check behaviour with regards to size of (visible) bounding box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
